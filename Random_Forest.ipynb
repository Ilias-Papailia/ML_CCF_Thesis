{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report,f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.metrics import geometric_mean_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')  \n",
    "scaler = StandardScaler()\n",
    "\n",
    "df['Amount'] = scaler.fit_transform(df[['Amount']])\n",
    "df['Time'] = scaler.fit_transform(df[['Time']])\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN SPLIT 80 % 20 % , HYPERPARAMETER TUNING FOR Random Forrest, STRATIFIED FOLD FOR VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "param_grid_cost = {\n",
    "    'n_estimators': [200,400,600],\n",
    "    'criterion' :[\"gini\",\"entropy\"],\n",
    "    'max_features' : ['sqrt','log2'],\n",
    "    'class_weight': [\"balanced\",{0: 1, 1: 1.5},{0: 1, 1: 1}, {0:1,1:2} , {0: 1, 1: 10},{0: 1, 1: 3},{0: 1, 1: 4},{0: 1, 1: 5},{0: 1, 1: 15},{0: 1, 1: 20}]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200,400,600],\n",
    "    'criterion' :[\"gini\",\"entropy\"],\n",
    "    'max_features' : ['sqrt','log2'],\n",
    "    #max depth / min sample split ( Tried those but lead to overfit)\n",
    "}\n",
    "\n",
    "param_grid_default = {}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION TO EVALUATE PERFORMANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(logistic, X_test, y_test):\n",
    "    y_pred = logistic.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    gmean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"f1-score: {f1}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Classification Report:\\n{classification_rep}\")\n",
    "    print(f\"Geometric Mean: {gmean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION FOR P R CURVE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRCurve(model,X_test,y_test,title):\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"Area Under the Precision-Recall Curve (AUPRC): {auprc}\")\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label='Precision-Recall curve',color='red')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=cv, scoring='f1',n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_baseline = grid_search.best_estimator_\n",
    "dump(rf_baseline, 'Models/rf_Baseline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_baseline = load('Models/rf_Baseline.joblib')\n",
    "evaluate_model_performance(rf_baseline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_baseline,X_test,y_test,\"PR Curve Hyperparameter Tuned Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNDERSAMPLING TECHNIQUES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomek Links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Tomek Link from previous Notebook (takes a long time to compute)\n",
    "with open('resampled_Tomek.pkl', 'rb') as file:\n",
    "    X_tomek, Y_tomek = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search_tl = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1,n_jobs=-1)\n",
    "grid_search_tl.fit(X_tomek, Y_tomek)\n",
    "grid_search_tl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tl = grid_search_tl.best_estimator_\n",
    "dump(rf_tl, 'Models/rf_TomekLink.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tomek = load('Models/rf_TomekLink.joblib')\n",
    "evaluate_model_performance(rf_tomek, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_tomek,X_test,y_test,\"PR Curve Random Forest Tomek LinK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Near Miss 3 Implementations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "nearMiss1 = NearMiss(version=1,n_jobs=-1)\n",
    "\n",
    "X_resampled_nm1, Y_resampled_nm1 = nearMiss1.fit_resample(X_train, y_train)\n",
    "\n",
    "grid_search_nm1 = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1,n_jobs=-1)\n",
    "grid_search_nm1.fit(X_resampled_nm1,Y_resampled_nm1)\n",
    "\n",
    "print(f\"Before resampling: {Counter(y_train)}\")\n",
    "print(f\"After resampling with NearMiss-1: {Counter(Y_resampled_nm1)}\")\n",
    "\n",
    "grid_search_nm1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_NearMiss1 = grid_search_nm1.best_estimator_\n",
    "dump(rf_NearMiss1, 'Models/rf_NearMiss1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_NearMiss1 = load('Models/rf_NearMiss1.joblib')\n",
    "evaluate_model_performance(rf_NearMiss1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_NearMiss1,X_test,y_test,\"PR Curve Random Forest NearMiss(1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Near Miss 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearMiss2 = NearMiss(version=2,n_jobs=-1)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "X_resampled_nm2, Y_resampled_nm2 = nearMiss2.fit_resample(X_train, y_train)\n",
    "\n",
    "grid_search_nm2 = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1,n_jobs=-1)\n",
    "grid_search_nm2.fit(X_resampled_nm2,Y_resampled_nm2)\n",
    "\n",
    "grid_search_nm2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_NearMiss2 = grid_search_nm2.best_estimator_\n",
    "dump(rf_NearMiss2, 'Models/rf_NearMiss2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_NearMiss2 = load('Models/rf_NearMiss2.joblib')\n",
    "evaluate_model_performance(rf_NearMiss2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_NearMiss2,X_test,y_test,\"PR Curve Random Forest NearMiss(2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Near Miss 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearMiss3 = NearMiss(version=3,n_jobs=-1)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "X_resampled_nm3, Y_resampled_nm3 = nearMiss3.fit_resample(X_train, y_train)\n",
    "\n",
    "grid_search_nm3 = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1,n_jobs=-1)\n",
    "grid_search_nm3.fit(X_resampled_nm3,Y_resampled_nm3)\n",
    "grid_search_nm3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_NearMiss3 = grid_search_nm3.best_estimator_\n",
    "dump(rf_NearMiss3, 'Models/rf_NearMiss3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_NearMiss3 = load('Models/rf_NearMiss3.joblib')\n",
    "evaluate_model_performance(rf_NearMiss3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_NearMiss3,X_test,y_test,\"PR Curve Random Forest NearMiss(3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERSAMPLING TECHNIQUES:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features shape: {X_train.shape}\")\n",
    "smote = SMOTE(random_state=42, n_jobs=-1)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "X_resampled_smote, Y_resampled_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Features shape: {X_resampled_smote.shape}\")\n",
    "\n",
    "grid_search_smote = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1,n_jobs=-1)\n",
    "grid_search_smote.fit(X_resampled_smote,Y_resampled_smote)\n",
    "grid_search_smote.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_smote = grid_search_smote.best_estimator_\n",
    "dump(rf_smote, 'Models/rf_Smote.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features shape: {X_train.shape}\")\n",
    "print(f\"Target shape: {y_train.shape}\")\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "\n",
    "print(f\"Features shape: {X_resampled_smote.shape}\")\n",
    "print(f\"Target shape: {Y_resampled_smote.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_SMOTE = load('Models/rf_Smote.joblib')\n",
    "evaluate_model_performance(rf_SMOTE, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_SMOTE,X_test,y_test,\"PR Curve Random Forest SMOTE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features shape: {X_train.shape}\")\n",
    "adasyn = ADASYN(random_state=42, n_jobs=-1)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "X_resampled_ad, Y_resampled_ad = adasyn.fit_resample(X_train, y_train)\n",
    "print(f\"Features shape: {X_resampled_ad.shape}\")\n",
    "\n",
    "grid_search_ad = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1,n_jobs=-1)\n",
    "grid_search_ad.fit(X_resampled_ad,Y_resampled_ad)\n",
    "grid_search_ad.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(grid_search_ad.best_estimator_, 'Models/rf_adasyn.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_adasyn = load('Models/rf_adasyn.joblib')\n",
    "evaluate_model_performance(rf_adasyn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_adasyn,X_test,y_test,\"PR Curve Random Forest ADASYN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BORDERLINE SMOTE 2 APPROACHES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BORDERLINE SMOTE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features shape: {X_train.shape}\")\n",
    "\n",
    "borderline_smote = BorderlineSMOTE(random_state=42, n_jobs=-1)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "X_resampled_bs, Y_resampled_bs = borderline_smote.fit_resample(X_train, y_train)\n",
    "print(f\"Features shape: {X_resampled_bs.shape}\")\n",
    "\n",
    "grid_search_bs = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search_bs.fit(X_resampled_bs, Y_resampled_bs)\n",
    "grid_search_bs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(grid_search_bs.best_estimator_, 'Models/rf_borderlinesmote1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Bsmote = load('Models/rf_borderlinesmote1.joblib')\n",
    "evaluate_model_performance(rf_Bsmote, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_Bsmote,X_test,y_test,\"PR Curve Random Forest BorderlineSMOTE(1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BORDERLINE SMOTE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features shape: {X_train.shape}\")\n",
    "\n",
    "borderline_smote2 = BorderlineSMOTE(random_state=42, n_jobs=-1,kind='borderline-2')\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "X_resampled_bs2, Y_resampled_bs2 = borderline_smote2.fit_resample(X_train, y_train)\n",
    "print(f\"Features shape: {X_resampled_bs2.shape}\")\n",
    "\n",
    "grid_search_bs2 = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search_bs2.fit(X_resampled_bs2, Y_resampled_bs2)\n",
    "grid_search_bs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_borderlinesmote2 = grid_search_bs2.best_estimator_\n",
    "dump(rf_borderlinesmote2, 'Models/rf_borderlinesmote2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_borderlinesmote2 = load('Models/rf_borderlinesmote2.joblib')\n",
    "evaluate_model_performance(rf_borderlinesmote2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_borderlinesmote2,X_test,y_test,\"PR Curve Random Forest BorderlineSMOTE(2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HYBRID APPROACHES :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resampled_data.pkl', 'rb') as file:\n",
    "    X_loaded, Y_loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smote_tomek = SMOTETomek(random_state=42, n_jobs=-1)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "X_resampled_st, Y_resampled_st = smote_tomek.fit_resample(X_train, y_train)\n",
    "print(f\"Features shape: {X_resampled_st.shape}\")\n",
    "\n",
    "grid_search_st = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search_st.fit(X_resampled_st, Y_resampled_st)\n",
    "grid_search_st.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_smoteTomek= grid_search_st.best_estimator_\n",
    "dump(rf_smoteTomek, 'Models/rf_smoteTtomek.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_smokeTomek = load('Models/rf_smoteTtomek.joblib')\n",
    "evaluate_model_performance(rf_smokeTomek,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_smoteTomek,X_test,y_test,\"PR Curve Random Forest SMOTETomek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(grid_search_st.best_params_,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTEENN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resampled_dataSmoteE.pkl', 'rb') as file:\n",
    "    X_loaded, Y_loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search_se = GridSearchCV(rf, param_grid, cv=cv, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search_se.fit(X_loaded, Y_loaded)\n",
    "grid_search_se.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features shape: (227845, 30)\n",
    " \n",
    "#Features shape after SMOTEENN: (454505, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_se = grid_search_se.best_estimator_\n",
    "dump(rf_se, 'Models/rf_smoteE.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_se = load( 'Models/rf_smoteE.joblib')\n",
    "evaluate_model_performance(rf_se,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_se,X_test,y_test,\"PR Curve Random Forest SMOTEENN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COST SENSITIVE LEARNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search_cost = GridSearchCV(rf, param_grid_cost, cv=cv, scoring='f1',n_jobs=-1)\n",
    "\n",
    "grid_search_cost.fit(X_train, y_train)\n",
    "grid_search_cost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cost = grid_search_cost.best_estimator_\n",
    "dump(rf_cost, 'Models/rf_costsensitive.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cost = load('Models/rf_costsensitive.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(rf_cost,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRCurve(rf_cost,X_test,y_test,\"PR Curve Random Forest Cost Sensitive Learning \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
